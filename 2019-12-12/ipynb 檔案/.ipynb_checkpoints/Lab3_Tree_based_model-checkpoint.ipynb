{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019-12-12\n",
    "## Lecture：Tree-Based Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into 'C:/Users/adm/Documents/R/win-library/3.6'\n",
      "(as 'lib' is unspecified)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'tree' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\adm\\AppData\\Local\\Temp\\RtmpOwfcRB\\downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "#install.packages('tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'> Decision tree</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We first use classification trees to analyze the<font color='red'> Carseats</font>  data set.\n",
    "### <font color='red'> Sales</font> is a continuous variable, and so we begin by recoding it as a binary variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in library(tree): there is no package called 'tree'\n",
     "output_type": "error",
     "traceback": [
      "Error in library(tree): there is no package called 'tree'\nTraceback:\n",
      "1. library(tree)"
     ]
    }
   ],
   "source": [
    "library(ISLR)\n",
    "library(tree)\n",
    "data(Carseats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "High = ifelse(Carseats$Sales <= 8, \"No\" ,\"Yes\")\n",
    "Carseats = data.frame(Carseats ,High)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(Carseats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now use the <font color='red'> tree()</font> function to fit a classification tree in order to predict tree() <font color='red'> high</font> using all variables but Sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.carseats = tree(High~.-Sales, data=Carseats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(tree.carseats )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The <font color='red'> summary()</font> function lists the variables that are used as internal nodes in the tree, the number of terminal nodes, and the (training) error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(tree.carseats)\n",
    "text(tree.carseats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to properly evaluate the performance of a classification tree on these data, we must estimate the test error rather than simply computing the training error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(2)\n",
    "train = sample (1:nrow(Carseats), 200) #50%訓練集 50%測試集\n",
    "Carseats.test = Carseats[-train, ]\n",
    "High.test = High[-train] #response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.carseats = tree(High~.-Sales , data = Carseats, subset = train)\n",
    "tree.pred = predict(tree.carseats ,Carseats.test ,type=\"class\") #指定type=\"class\"表示會回傳預測的種類\n",
    "table(tree.pred, High.test)#混淆矩陣\n",
    "mean(tree.pred==High.test)#測試集準確度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'> Bagging and Random Forests</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we apply bagging and random forests. Using the <font color='red'> randomForest</font> package in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages('randomForest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(randomForest)\n",
    "library(MASS)\n",
    "set.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(Carseats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The argument <font color='red'> mtry=10</font> indicates that all 10 predictors should be considered for each split of the tree—in other words, that bagging should be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By default, randomForest() uses $\\sqrt{p}$ variables when building a random forest of classification trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag.Carseats = randomForest(High~.-Sales, data = Carseats, mtry=10, ntree=500)\n",
    "bag.Carseats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the <font color='red'> varImpPlot()</font> function, we can view the importance of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varImpPlot(bag.Carseats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'> Practice</font>\n",
    "### Evaluate the performance of a RF on <font color='red'> Carseats</font> data, that is you can estimate the <font color='red'> test error</font> with different <font color='red'> mtry</font> or <font color='red'> ntree</font>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(20191212)\n",
    "train = sample (1:nrow(Carseats), 200) #50%訓練集 50%測試集\n",
    "Carseats.test = Carseats[-train, ]\n",
    "High.test = High[-train] #response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.Carseats = randomForest(High~.-Sales, data = Carseats, mtry=4, ntree=100, subset=train)\n",
    "rf.pred = predict(rf.Carseats ,Carseats.test ,type=\"class\") #指定type=\"class\"表示會回傳預測的種類\n",
    "table(rf.pred, High.test)#混淆矩陣\n",
    "mean(rf.pred==High.test)#測試集準確度"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
